{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from ast import literal_eval\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Images\n",
    "\n",
    "Create a dataframe containing the image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in folder: 98\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>019822ed-bf5b-4cc7-b911-4ee529d8f28b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3f6c0737-611b-4e39-9508-231e72a40125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fb0d4981-0106-47a7-acec-c1bb0e0f8c87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21c20f6c-fb82-44a8-b61b-26f0ad36bf87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5d98c050-74eb-42ad-85d6-b7fb779d24d2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id\n",
       "0  019822ed-bf5b-4cc7-b911-4ee529d8f28b\n",
       "1  3f6c0737-611b-4e39-9508-231e72a40125\n",
       "2  fb0d4981-0106-47a7-acec-c1bb0e0f8c87\n",
       "3  21c20f6c-fb82-44a8-b61b-26f0ad36bf87\n",
       "4  5d98c050-74eb-42ad-85d6-b7fb779d24d2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Location of dataset\n",
    "DATASET_PATH = \"../data/01_raw\"\n",
    "\n",
    "# List all images in the folder\n",
    "image_list = [\n",
    "    filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    for filename in glob(DATASET_PATH + \"/images/*.jpg\")\n",
    "]\n",
    "image_ids = pd.DataFrame(image_list).rename(columns={0: \"image_id\"})\n",
    "print(\"Number of images in folder: {}\".format(len(image_ids)))\n",
    "\n",
    "image_ids.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Annotations\n",
    "\n",
    "Add the bounding box informations to the dataframe. A bounding box is a rectangle around the object detected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0918a15c-8cfb-4da7-92cf-1f5098a76760</td>\n",
       "      <td>oil-storage-tank</td>\n",
       "      <td>(1205, 1493, 1231, 1516)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0918a15c-8cfb-4da7-92cf-1f5098a76760</td>\n",
       "      <td>oil-storage-tank</td>\n",
       "      <td>(1479, 1756, 1507, 1776)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0918a15c-8cfb-4da7-92cf-1f5098a76760</td>\n",
       "      <td>oil-storage-tank</td>\n",
       "      <td>(1478, 1786, 1518, 1815)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0918a15c-8cfb-4da7-92cf-1f5098a76760</td>\n",
       "      <td>oil-storage-tank</td>\n",
       "      <td>(2132, 2163, 2148, 2178)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0918a15c-8cfb-4da7-92cf-1f5098a76760</td>\n",
       "      <td>oil-storage-tank</td>\n",
       "      <td>(2010, 2127, 2024, 2141)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_id             class  \\\n",
       "0  0918a15c-8cfb-4da7-92cf-1f5098a76760  oil-storage-tank   \n",
       "1  0918a15c-8cfb-4da7-92cf-1f5098a76760  oil-storage-tank   \n",
       "2  0918a15c-8cfb-4da7-92cf-1f5098a76760  oil-storage-tank   \n",
       "3  0918a15c-8cfb-4da7-92cf-1f5098a76760  oil-storage-tank   \n",
       "4  0918a15c-8cfb-4da7-92cf-1f5098a76760  oil-storage-tank   \n",
       "\n",
       "                     bounds  \n",
       "0  (1205, 1493, 1231, 1516)  \n",
       "1  (1479, 1756, 1507, 1776)  \n",
       "2  (1478, 1786, 1518, 1815)  \n",
       "3  (2132, 2163, 2148, 2178)  \n",
       "4  (2010, 2127, 2024, 2141)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert a string record into a valid python object\n",
    "def convert_string_to_python_object(x):\n",
    "    return literal_eval(x.rstrip(\"\\r\\n\"))\n",
    "\n",
    "\n",
    "# read the CSV with annotations\n",
    "labels = pd.read_csv(\n",
    "    DATASET_PATH + \"/annotations.csv\",\n",
    "    converters={\"bounds\": convert_string_to_python_object},\n",
    ")\n",
    "\n",
    "\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_names, test_image_names = train_test_split(image_list, test_size=0.2)\n",
    "val_image_names, test_image_names = train_test_split(test_image_names, test_size=0.5)\n",
    "\n",
    "print(\n",
    "    f\"The trainings dataset contains {len(train_image_names)} images. Thats {round(len(train_image_names)/len(image_list) *100)}%.\"\n",
    ")\n",
    "print(\n",
    "    f\"The test dataset contains {len(test_image_names)} images. Thats {round(len(test_image_names)/len(image_list) *100)}%.\"\n",
    ")\n",
    "print(\n",
    "    f\"The validation dataset contains {len(val_image_names)} images. Thats {round(len(val_image_names)/len(image_list) *100)}%.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bounding box information\n",
    "train_df = labels[labels[\"image_id\"].isin(train_image_names)]\n",
    "valid_df = labels[labels[\"image_id\"].isin(val_image_names)]\n",
    "test_df = labels[labels[\"image_id\"].isin(test_image_names)]\n",
    "\n",
    "# write datasets to disk\n",
    "os.makedirs(\"../data/04_feature/annotations\", exist_ok=True)\n",
    "train_df.to_csv(\"../data/04_feature/annotations/train.csv\", index=False)\n",
    "valid_df.to_csv(\"../data/04_feature/annotations/valid.csv\", index=False)\n",
    "test_df.to_csv(\"../data/04_feature/annotations/test.csv\", index=False)\n",
    "\n",
    "# copy images to model_input folder\n",
    "os.makedirs(\"../data/04_feature/images/train\", exist_ok=True)\n",
    "for image_name in train_image_names:\n",
    "    shutil.copy(\n",
    "        f\"../data/01_raw/images/{image_name}.jpg\",\n",
    "        f\"../data/04_feature/images/train/{image_name}.jpg\",\n",
    "    )\n",
    "os.makedirs(\"../data/04_feature/images/validation\", exist_ok=True)\n",
    "for image_name in val_image_names:\n",
    "    shutil.copy(\n",
    "        f\"../data/01_raw/images/{image_name}.jpg\",\n",
    "        f\"../data/04_feature/images/validation/{image_name}.jpg\",\n",
    "    )\n",
    "os.makedirs(\"../data/04_feature/images/test\", exist_ok=True)\n",
    "for image_name in test_image_names:\n",
    "    shutil.copy(\n",
    "        f\"../data/01_raw/images/{image_name}.jpg\",\n",
    "        f\"../data/04_feature/images/test/{image_name}.jpg\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to tensorflow records dataset\n",
    "\n",
    "The TFRecord format is a simple format for storing a sequence of binary records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_records_from_files(\n",
    "    image_path: str | Path, annotations_file_path: str | Path\n",
    ") -> list[tf.train.Example]:\n",
    "\n",
    "    image_path = Path(image_path)\n",
    "    annotations_file_path = Path(annotations_file_path)\n",
    "\n",
    "    annotations = pd.read_csv(annotations_file_path)\n",
    "\n",
    "    def expand_bbox_coordinates(row: pd.Series):\n",
    "        bbox_as_tuple = literal_eval(row[\"bounds\"])\n",
    "        row[\"bbox_x1\"] = bbox_as_tuple[0]\n",
    "        row[\"bbox_y1\"] = bbox_as_tuple[1]\n",
    "        row[\"bbox_x2\"] = bbox_as_tuple[2]\n",
    "        row[\"bbox_y2\"] = bbox_as_tuple[3]\n",
    "\n",
    "        return row\n",
    "\n",
    "    annotations = annotations.apply(expand_bbox_coordinates, 1)\n",
    "\n",
    "    annotations.drop([\"class\", \"bounds\"], axis=1, inplace=True)\n",
    "\n",
    "    image_filenames = os.listdir(image_path)\n",
    "\n",
    "    tf_records = []\n",
    "\n",
    "    for image_filename in image_filenames:\n",
    "        with tf.gfile.GFile(image_path / image_filename, \"rb\") as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "\n",
    "        image_width = 2560\n",
    "        image_height = 2560\n",
    "\n",
    "        filename = image_filename.encode(\"utf8\")\n",
    "        image_format = b\"jpg\"\n",
    "\n",
    "        annotations_filtered = annotations[\n",
    "            annotations[\"image_id\"] == image_filename[:-4]\n",
    "        ]\n",
    "\n",
    "        xmins = annotations_filtered[\"bbox_x1\"].values\n",
    "        xmaxs = annotations_filtered[\"bbox_x2\"].values\n",
    "        ymins = annotations_filtered[\"bbox_y1\"].values\n",
    "        ymaxs = annotations_filtered[\"bbox_y2\"].values\n",
    "\n",
    "        class_name = \"OST\".encode(\"utf8\")\n",
    "\n",
    "        classes_text = [class_name for i in range(len(xmins))]\n",
    "        classes = [1 for i in range(len(xmins))]\n",
    "\n",
    "        tf_records.append(\n",
    "            tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                        \"image/height\": dataset_util.int64_feature(image_height),\n",
    "                        \"image/width\": dataset_util.int64_feature(image_width),\n",
    "                        \"image/filename\": dataset_util.bytes_feature(filename),\n",
    "                        \"image/source_id\": dataset_util.bytes_feature(filename),\n",
    "                        \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
    "                        \"image/format\": dataset_util.bytes_feature(image_format),\n",
    "                        \"image/object/bbox/xmin\": dataset_util.float_list_feature(\n",
    "                            xmins\n",
    "                        ),\n",
    "                        \"image/object/bbox/xmax\": dataset_util.float_list_feature(\n",
    "                            xmaxs\n",
    "                        ),\n",
    "                        \"image/object/bbox/ymin\": dataset_util.float_list_feature(\n",
    "                            ymins\n",
    "                        ),\n",
    "                        \"image/object/bbox/ymax\": dataset_util.float_list_feature(\n",
    "                            ymaxs\n",
    "                        ),\n",
    "                        \"image/object/class/text\": dataset_util.bytes_list_feature(\n",
    "                            classes_text\n",
    "                        ),\n",
    "                        \"image/object/class/label\": dataset_util.int64_list_feature(\n",
    "                            classes\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return tf_records\n",
    "\n",
    "\n",
    "def save_tf_records_to_file(\n",
    "    tf_records: list[tf.train.Example], output_path: str | Path\n",
    "):\n",
    "    writer = tf.python_io.TFRecordWriter(output_path)\n",
    "\n",
    "    for record in tf_records:\n",
    "        writer.write(record.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_records = create_tf_records_from_files(\n",
    "    \"../data/04_feature/images/train/\",\n",
    "    \"../data/04_feature/annotations/train.csv\",\n",
    "    \"../data/04_feature/annotations/label_map.pbtxt\",\n",
    ")\n",
    "\n",
    "tf_test_records = create_tf_records_from_files(\n",
    "    \"../data/04_feature/images/test/\",\n",
    "    \"../data/04_feature/annotations/test.csv\",\n",
    "    \"../data/04_feature/annotations/label_map.pbtxt\",\n",
    ")\n",
    "\n",
    "tf_valid_records = create_tf_records_from_files(\n",
    "    \"../data/04_feature/images/test/\",\n",
    "    \"../data/04_feature/annotations/valid.csv\",\n",
    "    \"../data/04_feature/annotations/label_map.pbtxt\",\n",
    ")\n",
    "\n",
    "save_tf_records_to_file(tf_train_records, \"../data/05_model_input/train.record\")\n",
    "\n",
    "save_tf_records_to_file(tf_test_records, \"../data/05_model_input/test.record\")\n",
    "\n",
    "save_tf_records_to_file(tf_test_records, \"../data/05_model_input/test.record\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f106c9174396cfd4f95306457e07ca9b5d0acb34d2ac2a48a34ee63ebd5c4168"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-osd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
