{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from ast import literal_eval\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1: Images\n",
        "\n",
        "Create a dataframe containing the image names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Location of dataset\n",
        "DATASET_PATH = \"../data/01_raw\"\n",
        "\n",
        "# List all images in the folder\n",
        "image_list = [\n",
        "    filename.split(\"/\")[-1].split(\".\")[0]\n",
        "    for filename in glob(DATASET_PATH + \"/images/*.jpg\")\n",
        "]\n",
        "image_ids = pd.DataFrame(image_list).rename(columns={0: \"image_id\"})\n",
        "print(\"Number of images in folder: {}\".format(len(image_ids)))\n",
        "\n",
        "image_ids.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: Annotations\n",
        "\n",
        "Add the bounding box informations to the dataframe. A bounding box is a rectangle around the object detected. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert a string record into a valid python object\n",
        "def convert_string_to_python_object(x):\n",
        "    return literal_eval(x.rstrip(\"\\r\\n\"))\n",
        "\n",
        "\n",
        "# read the CSV with annotations\n",
        "labels = pd.read_csv(\n",
        "    DATASET_PATH + \"/annotations.csv\",\n",
        "    converters={\"bounds\": convert_string_to_python_object},\n",
        ")\n",
        "\n",
        "\n",
        "labels.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train Test Split\n",
        "\n",
        "The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_image_names, test_image_names = train_test_split(image_list, test_size=0.2)\n",
        "val_image_names, test_image_names = train_test_split(test_image_names, test_size=0.5)\n",
        "\n",
        "print(\n",
        "    f\"The trainings dataset contains {len(train_image_names)} images. Thats {round(len(train_image_names)/len(image_list) *100)}%.\"\n",
        ")\n",
        "print(\n",
        "    f\"The test dataset contains {len(test_image_names)} images. Thats {round(len(test_image_names)/len(image_list) *100)}%.\"\n",
        ")\n",
        "print(\n",
        "    f\"The validation dataset contains {len(val_image_names)} images. Thats {round(len(val_image_names)/len(image_list) *100)}%.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add bounding box information\n",
        "train_df = labels[labels[\"image_id\"].isin(train_image_names)]\n",
        "valid_df = labels[labels[\"image_id\"].isin(val_image_names)]\n",
        "test_df = labels[labels[\"image_id\"].isin(test_image_names)]\n",
        "\n",
        "# write datasets to disk\n",
        "os.makedirs(\"../data/04_feature/annotations\", exist_ok=True)\n",
        "train_df.to_csv(\"../data/04_feature/annotations/train.csv\", index=False)\n",
        "valid_df.to_csv(\"../data/04_feature/annotations/valid.csv\", index=False)\n",
        "test_df.to_csv(\"../data/04_feature/annotations/test.csv\", index=False)\n",
        "\n",
        "# copy images to model_input folder\n",
        "os.makedirs(\"../data/04_feature/images/train\", exist_ok=True)\n",
        "for image_name in train_image_names:\n",
        "    shutil.copy(\n",
        "        f\"../data/01_raw/images/{image_name}.jpg\",\n",
        "        f\"../data/04_feature/images/train/{image_name}.jpg\",\n",
        "    )\n",
        "os.makedirs(\"../data/04_feature/images/validation\", exist_ok=True)\n",
        "for image_name in val_image_names:\n",
        "    shutil.copy(\n",
        "        f\"../data/01_raw/images/{image_name}.jpg\",\n",
        "        f\"../data/04_feature/images/validation/{image_name}.jpg\",\n",
        "    )\n",
        "os.makedirs(\"../data/04_feature/images/test\", exist_ok=True)\n",
        "for image_name in test_image_names:\n",
        "    shutil.copy(\n",
        "        f\"../data/01_raw/images/{image_name}.jpg\",\n",
        "        f\"../data/04_feature/images/test/{image_name}.jpg\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert data to tensorflow records dataset\n",
        "\n",
        "The TFRecord format is a simple format for storing a sequence of binary records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from ast import literal_eval\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "from object_detection.utils import dataset_util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_records_from_files(\n",
        "    image_path: str | Path, annotations_file_path: str | Path\n",
        ") -> list[tf.train.Example]:\n",
        "\n",
        "    image_path = Path(image_path)\n",
        "    annotations_file_path = Path(annotations_file_path)\n",
        "\n",
        "    annotations = pd.read_csv(annotations_file_path)\n",
        "\n",
        "    def expand_bbox_coordinates(row: pd.Series):\n",
        "        bbox_as_tuple = literal_eval(row[\"bounds\"])\n",
        "        row[\"bbox_x1\"] = bbox_as_tuple[0]\n",
        "        row[\"bbox_y1\"] = bbox_as_tuple[1]\n",
        "        row[\"bbox_x2\"] = bbox_as_tuple[2]\n",
        "        row[\"bbox_y2\"] = bbox_as_tuple[3]\n",
        "\n",
        "        return row\n",
        "\n",
        "    annotations = annotations.apply(expand_bbox_coordinates, 1)\n",
        "\n",
        "    annotations.drop([\"class\", \"bounds\"], axis=1, inplace=True)\n",
        "\n",
        "    image_filenames = os.listdir(image_path)\n",
        "\n",
        "    tf_records = []\n",
        "\n",
        "    for image_filename in image_filenames:\n",
        "        with tf.gfile.GFile(image_path / image_filename, \"rb\") as fid:\n",
        "            encoded_jpg = fid.read()\n",
        "\n",
        "        image_width = 2560\n",
        "        image_height = 2560\n",
        "\n",
        "        filename = image_filename.encode(\"utf8\")\n",
        "        image_format = b\"jpg\"\n",
        "\n",
        "        annotations_filtered = annotations[\n",
        "            annotations[\"image_id\"] == image_filename[:-4]\n",
        "        ]\n",
        "\n",
        "        xmins = annotations_filtered[\"bbox_x1\"].values\n",
        "        xmaxs = annotations_filtered[\"bbox_x2\"].values\n",
        "        ymins = annotations_filtered[\"bbox_y1\"].values\n",
        "        ymaxs = annotations_filtered[\"bbox_y2\"].values\n",
        "\n",
        "        class_name = \"OST\".encode(\"utf8\")\n",
        "\n",
        "        classes_text = [class_name for i in range(len(xmins))]\n",
        "        classes = [1 for i in range(len(xmins))]\n",
        "\n",
        "        tf_records.append(\n",
        "            tf.train.Example(\n",
        "                features=tf.train.Features(\n",
        "                    feature={\n",
        "                        \"image/height\": dataset_util.int64_feature(image_height),\n",
        "                        \"image/width\": dataset_util.int64_feature(image_width),\n",
        "                        \"image/filename\": dataset_util.bytes_feature(filename),\n",
        "                        \"image/source_id\": dataset_util.bytes_feature(filename),\n",
        "                        \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
        "                        \"image/format\": dataset_util.bytes_feature(image_format),\n",
        "                        \"image/object/bbox/xmin\": dataset_util.float_list_feature(\n",
        "                            xmins\n",
        "                        ),\n",
        "                        \"image/object/bbox/xmax\": dataset_util.float_list_feature(\n",
        "                            xmaxs\n",
        "                        ),\n",
        "                        \"image/object/bbox/ymin\": dataset_util.float_list_feature(\n",
        "                            ymins\n",
        "                        ),\n",
        "                        \"image/object/bbox/ymax\": dataset_util.float_list_feature(\n",
        "                            ymaxs\n",
        "                        ),\n",
        "                        \"image/object/class/text\": dataset_util.bytes_list_feature(\n",
        "                            classes_text\n",
        "                        ),\n",
        "                        \"image/object/class/label\": dataset_util.int64_list_feature(\n",
        "                            classes\n",
        "                        ),\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return tf_records\n",
        "\n",
        "\n",
        "def save_tf_records_to_file(\n",
        "    tf_records: list[tf.train.Example], output_path: str | Path\n",
        "):\n",
        "    writer = tf.python_io.TFRecordWriter(output_path)\n",
        "\n",
        "    for record in tf_records:\n",
        "        writer.write(record.SerializeToString())\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def label_map(file_path: str, objname: str):\n",
        "    with open(Path(file_path), \"a\") as the_file:\n",
        "        the_file.write(\"item\\n\")\n",
        "        the_file.write(\"{\\n\")\n",
        "        the_file.write(\"id :{}\".format(int(1)))\n",
        "        the_file.write(\"\\n\")\n",
        "        the_file.write(\"name :'{0}'\".format(str(objname)))\n",
        "        the_file.write(\"\\n\")\n",
        "        the_file.write(\"}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Write data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create label map with one object: oil-storage-tank (OSD)\n",
        "label_map(\"../data/04_feature/annotations/label_map.pbtxt\", \"OSD\")\n",
        "\n",
        "# create tfrecords from images and annotations \n",
        "tf_train_records = create_tf_records_from_files(\n",
        "    \"../data/04_feature/images/train/\",\n",
        "    \"../data/04_feature/annotations/train.csv\"\n",
        ")\n",
        "\n",
        "tf_test_records = create_tf_records_from_files(\n",
        "    \"../data/04_feature/images/test/\",\n",
        "    \"../data/04_feature/annotations/test.csv\"\n",
        ")\n",
        "\n",
        "tf_valid_records = create_tf_records_from_files(\n",
        "    \"../data/04_feature/images/validation/\",\n",
        "    \"../data/04_feature/annotations/valid.csv\"\n",
        ")\n",
        "\n",
        "# write tfrecord files to disk \n",
        "save_tf_records_to_file(tf_train_records, \"../data/05_model_input/train.record\")\n",
        "\n",
        "save_tf_records_to_file(tf_test_records, \"../data/05_model_input/test.record\")\n",
        "\n",
        "save_tf_records_to_file(tf_valid_records, \"../data/05_model_input/valid.record\")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ba2a370e0a0b46148d0bc6f0dacc2945484703f96f66df7fdf5d2762f5da2b4c"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('osd')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
